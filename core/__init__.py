"""Core utilities for speech model experiments."""

from .data import (
    add_duration,
    build_manifest,
    build_split_metadata,
    compute_speaker_stats,
    compute_split_hours,
    dump_json,
    ensure_dir,
    filter_dataset_columns,
    hours_key,
    hours_to_seconds,
    load_cached_split,
    load_config,
    normalize_audio,
    normalize_split_metadata,
    num_proc_map_kwargs,
    resolve_num_proc,
    save_cached_split,
    select_indices_by_duration,
    select_random_indices,
    subset_dataset_by_metadata,
)
from .evaluation import (
    TaskEvalSetup,
    compute_wer_from_texts,
    decode_tokens,
    get_registered_eval_tasks,
    load_model_and_processor,
    plot_confusion_matrix,
    plot_loss_and_wer,
    prepare_task_for_evaluation,
    register_eval_task,
    run_evaluation,
    sanitize_token_array,
)
from .models import load_qwen_asr_model, load_qwen_model
from .training import (
    BalancedBatchSampler,
    CustomTrainer,
    TrainingConfig,
    WeightedClassSampler,
    build_early_stopping_kwargs,
    build_history_record,
    build_training_arguments,
    create_classification_constraint,
    create_multi_token_constraint,
    parse_training_config,
    run_training_with_evaluation,
    save_artifacts,
    save_history_to_csv,
)
from .utils import set_global_seed, setup_logger

__all__ = [
    "dump_json",
    "ensure_dir",
    "load_config",
    "add_duration",
    "build_manifest",
    "build_split_metadata",
    "compute_speaker_stats",
    "compute_split_hours",
    "filter_dataset_columns",
    "hours_key",
    "hours_to_seconds",
    "load_cached_split",
    "normalize_audio",
    "normalize_split_metadata",
    "num_proc_map_kwargs",
    "resolve_num_proc",
    "save_cached_split",
    "select_indices_by_duration",
    "select_random_indices",
    "subset_dataset_by_metadata",
    "setup_logger",
    "compute_wer_from_texts",
    "decode_tokens",
    "sanitize_token_array",
    "load_qwen_asr_model",
    "load_qwen_model",
    "load_model_and_processor",
    "prepare_task_for_evaluation",
    "register_eval_task",
    "get_registered_eval_tasks",
    "TaskEvalSetup",
    "run_evaluation",
    "plot_loss_and_wer",
    "plot_confusion_matrix",
    "set_global_seed",
    "BalancedBatchSampler",
    "CustomTrainer",
    "WeightedClassSampler",
    "save_artifacts",
    "save_history_to_csv",
    "TrainingConfig",
    "parse_training_config",
    "build_training_arguments",
    "build_early_stopping_kwargs",
    "build_history_record",
    "create_classification_constraint",
    "create_multi_token_constraint",
    "run_training_with_evaluation",
]
