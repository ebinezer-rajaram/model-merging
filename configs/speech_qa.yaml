# Speech Question Answering Task Configuration

task: speech_qa
seed: 0

# Model Configuration
model:
  path: data/models/Qwen2.5-Omni-3B
  lora:
    r: 64                             # LoRA rank
    alpha: 128                        # LoRA alpha scaling factor
    dropout: 0.1                      # Dropout probability for LoRA layers
    bias: none                        # Bias type: none, all, or lora_only
    target_modules:                   # Modules to apply LoRA to
      - q_proj                        # Query projection for attention
      - k_proj                        # Key projection
      - v_proj                        # Value projection
      - o_proj                        # Output projection
      - audio_tower.proj              # Critical for acoustic embeddings
      - gate_proj                     # MLP gating for complex reasoning
      - up_proj                       # MLP expansion for representation
      - down_proj                     # MLP projection
    task_type: CAUSAL_LM

# Dataset Configuration
dataset:
  # Source
  dataset_name: local_spoken_squad      # Use local GitHub Spoken-SQuAD checkout
  dataset_config: null
  data_dir: data/datasets/Spoken-SQuAD  # Root containing spoken_*.json and wav/{train,test}
  train_json: spoken_train-v1.1.json
  test_json: spoken_test-v1.1.json
  audio_root: null                       # null => <data_dir>/wav
  noisy_test_variant: none               # Options: none, wer44, wer54
  min_wavs_per_split: 100                # Fail fast when wav extraction is missing/incomplete
  max_missing_audio_rate: 0.05            # Allow unresolved QA->audio mappings to be dropped without failing
  allow_train_only_fallback: true        # If test wavs are missing, derive all splits from train
  audio_merge_policy: concatenate_sentences  # Options: first_sentence, concatenate_sentences
  # Processing
  seed: 0
  num_proc: auto
  cache_splits: true
  force_rebuild: false
  # Sample limits
  max_total_samples: 6000             # Auto-distribute across train/validation/test after split
  max_train_samples: null              # Leave null when using max_total_samples
  max_validation_samples: null
  max_test_samples: null
  # Audio filtering
  max_duration: 60.0                  # Filter out very long audio
  min_duration: 1.0                   # Filter out very short clips
  # Column mappings
  audio_column: null                  # Will auto-detect 'context' via fallback logic
  question_column: null               # Will auto-detect 'instruction' via fallback logic
  answer_column: null                 # Will auto-detect 'answer' via fallback logic
  transcript_column: null             # No transcript in this dataset
  context_column: null                # Not using text context
  id_column: null                     # No ID column
  # Splits
  split_percentages:                    # Derive train/validation/test from train source when needed
    train: 0.80
    validation: 0.10
    test: 0.10
  train_split: train
  validation_split: null
  test_split: test
  # Task-specific
  include_transcript: false           # No transcript available, audio-only QA
  include_context: false              # No text passage context

# Training Configuration
training:
  # Compute & batching
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 4
  bf16: true
  fp16: false
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  # Optimization
  learning_rate: 5e-5
  lr_scheduler_type: cosine
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  # Schedule
  num_train_epochs: 4
  eval_strategy: steps
  eval_steps: 20
  save_strategy: steps
  save_steps: 20
  initial_eval: true
  # Checkpointing
  save_total_limit: 3
  resume_from_checkpoint: null        # Options: null (start fresh), "auto" (detect latest), or explicit path
  # Early stopping
  early_stopping_patience: 4
  early_stopping_threshold: 0.001
  load_best_model_at_end: true
  metric_for_best_model: eval_f1
  greater_is_better: true
  # Data loading
  dataloader_num_workers: 8
  dataloader_pin_memory: true
  dataloader_prefetch_factor: 4
  group_by_length: true
  length_column_name: duration
  # Evaluation
  max_eval_samples: null              # Use subset during training for speed (null = full eval)
  shuffle_eval_subset: false
  eval_accumulation_steps: 4
  remove_unused_columns: false
  label_preflight_samples: 0        # Decode a small batch and verify label targets before training
  label_preflight_mismatch_threshold: 0
  # Logging
  logging_steps: 2
  report_to:
    - tensorboard
  # Generation
  generation_kwargs:
    max_new_tokens: 24                # Extractive spans should be short
    do_sample: false                  # Greedy decoding for deterministic results
    num_beams: 1

# Artifacts Configuration
artifacts:
  adapter_subdir: qwen2_5_omni_lora_speech_qa

# Metrics Configuration
metrics:
  history_csv: speech_qa_training_history.csv
  loss_plot: speech_qa_loss_metrics.png
  debug_eval_dump_samples: 10
